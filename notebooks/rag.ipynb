{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader, SeleniumURLLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = \"https://hackernoon.com/vector-databases-getting-started-with-chromadb-and-more\"\n",
    "\n",
    "def load_document(loader_class, website_url):\n",
    "    loader = loader_class([website_url])\n",
    "    return loader.load()\n",
    "\n",
    "#wb_loader_doc = load_document(WebBaseLoader, website)\n",
    "#wb_loader_doc[0].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selenium_loader_doc = load_document(SeleniumURLLoader, website)\n",
    "#selenium_loader_doc[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=200)\n",
    "#splits = text_splitter.split_documents(selenium_loader_doc)\n",
    "#splits[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = chromadb.PersistentClient(path=\"/src/database/chroma_data\")\n",
    "\n",
    "#client = chromadb.HttpClient(host=\"localhost\", port=8000)\n",
    "#collection = client.create_collection(\"open2_collection\", embedding_function=embedding_functions.OpenAIEmbeddingFunction(api_key=os.environ[\"OPENAI_API_KEY\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection = client.get_collection(\"open2_collection\")\n",
    "#for n in range(0, 10):\n",
    "#   collection.add(documents=[splits[n].page_content], ids=['id' + str(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the question based only on the following context:\n",
    "    Context: {context} \n",
    "    Question: {question} \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_texts([\"PA is working at SAP\", \n",
    "                                 \"PA also participates in a non-profit project\", \n",
    "                                 \"PA's fav pokemon is Snorlax\",\n",
    "                                 \"PA likes tacos\"], embedding=OpenAIEmbeddings())\n",
    "#vectorstore.persist()\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context provided, we can tell that PA is involved in a non-profit project, works at SAP, has Snorlax as their favorite Pokemon, and likes tacos.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"What can you tell me about PA?\")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodalgenai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
